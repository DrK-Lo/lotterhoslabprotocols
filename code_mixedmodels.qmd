# Linear Mixed Effect Models

Here are some of Lotterhos' notes on learning how to mix model

We have a private [google drive with many of the resources](https://drive.google.com/drive/folders/1L70xzfNel7eTYSbX0ZnmmvmBOL0iC4bO?usp=sharing)

### How to understand random effects

What are random effects? These are factors that may influence the values you observe, but are not factors that are being manipulated in an experiment. In other words, they are not effects that you care about the particular direction of and that you assume arise from a larger distribution, and you just need to control for in the experiment because they cause non-independence among datapoints within that level of teh factor. For example, in our oyster field experiment, we had oysters from each population deployed in 3 replicate bags per site. Each bag would have experienced slightly different conditions that would influence oyster depending on where they were deployed and sedimentation, water flow, and fouling of the bags. 
 
To understand random effects in your data, first run a model without the factor(s) you are thinking about incorporating into the model as random effects. Then, boxplot the residuals from that model (`resids()`) as a function of the factor(s) you are thinking about incorporating into the model as random effects. If the mean of the residuals varies a lot from level to level of the factor, then you should definitely include it as a random effect in the model. 

[To do add an example]

### Learn about `lme`

[Mixed Effects Models and Extensions in Ecology with R - Zuur](https://drive.google.com/file/d/1wmcZeZPiNoUtrrImV72fRI73MbVaD2gZ/view?usp=sharing)
  * If you have taken intro Biostats, review lectures on general linear models, simple linear and multiple regression, 
ANCOVA, and their assumptions, and likelihood before starting in with this book. Then review and learn new ways to test for assumptions in Chapter 2. 
You should also review matrix algebra.
	* This is an older book published in 2008, but much of which is still relevant.
	* Testing assumptions - Chapter 2
	* Learn about dealing with heterogeneity of variance in Chapter 4
	*  Mixed effects models and additive mixed effects models in Chapters 5,6,and7.
		* This book uses the `nlme` packages and the `lme` function, which has different syntax than lme4. However, the introduction to mixed modeling in Chapter 5 is an excellent place to start learning. Note that `lme` gives P-values for model effects, but we recommend using `lme4` with `lmertest` to generate these, or the package `brms` to take a Bayesian approach. 
		* Chapter 5 exlplains the difference between the random intercept model, the random intercept and slope model, and the random affection model.
		* Section 5.7 talks about model selection and should be read, but `lmertest` offers better options for this
		* Chapter 6 - dealing with autocorrelation in regularly spaced time series intervals.
	* Generalized GLM and GAMs (Chap 8-11)
		* Chap 8 is a good introduction to different distributions that you can assume your data follow, and distributions to use if your response variable does not include 0 (zero-truncated)
		* Chapter 9 has a good section on overdispersion
		* Chap 10 dedicated to proportional and presence/absence data
		* Chap 11 zero-truncated and inflated models
	* Chapter 12-13 GEEs (generalized estimating equations) for repeated measures and longitudinal data
		* In Chapters 12 and 13, we concentrated on mod- els that allow for correlation and random effects in Poisson and binomial GLMs and GAMs. These models are called generalised estimation equations (GEE), gener- alised linear mixed modelling (GLMM), and generalised additive mixed modelling (GAMM). 


### Learn `lme4` 

* [lme4 paper](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf)
	* good explanations of the form of the models and syntax
	* this paper has several sections on the mathematical details of the implementation, which can be skimmed, but be sure to pay attention again starting at 5.2
	* for the sections "... and model comparison" and "Computing P-values" here on page 34+, be sure to read `lmertest`for a better alternative
	
* [Mixed model theory](https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf)
	* This can be skimmed

* [PLS vs GLS for linear mixed models](https://cran.r-project.org/web/packages/lme4/vignettes/PLSvGLS.pdf)
	* This can be skimmed

[Performance tips](https://cran.r-project.org/web/packages/lme4/vignettes/lmerperf.html)
	* This can be skimmed

[tutorial with nested random effects](http://www.bodowinter.com/tutorial/bw_LME_tutorial.pdf)


### Learn about approximating degrees of freedom, getting P-values, and model selection from lme4 with `lmertest`

If `lme4` and REML offers good convergence for your model, then you may want to consider testing the significance of fixed 
and random effects with the `lmertest` package.

[lmertest paper](https://www.jstatsoft.org/article/view/v082i13)

[vignette](http://www2.compute.dtu.dk/courses/02930/SummerschoolMaterialWeb/Readingmaterial/MixedModels-TuesdayandFriday/Packageandtutorialmaterial/lmerTestTutorial.pdf)


### Good online tutorials

* [LM Tutorial 1](http://www.bodowinter.com/tutorial/bw_LME_tutorial1.pdf) 
This is a good intro to basic linear models output and assumptions.

* [LME Tutorial](http://www.bodowinter.com/tutorial/bw_LME_tutorial.pdf) Good intro to mixed effect models. 
Uses likelihood ratio tests to compare models. Has a good section on random slopes vs. random intercepts. 
Has some citations "Moreover, researchers in ecology (Schielzeth & Forstmeier, 2009),
psycholinguistics (Barr, Levy, Scheepers, & Tilly, 2013) and other fields have
shown via simulations that mixed models without random slopes are anticonservative or, in other words, 
they have a relatively high Type I error rate (they
tend to find a lot of significant results which are actually due to chance)."

### Learn about Bayesian Regression Models `brms`

The `brms` package offers the most versatility for modeling data, and can accommodate a whole family of different distributions. It even allows you to define your own functions and estimate parameters on those, and has a framework for hypothesis comparison of different effects with Bayes Factors. We've found this package is able to more accurately estimate parameters on methylation data than other packages.

For example in Alan's 2017 oyster exposure experiment: methylation data is binomially distributed (e.g., read counts for methylated or unmethylated) and in our case, we wanted to make sure to account for the random effect of tank in the experiment (see results). For some  loci, we found with preliminary analyses that some approaches to generalized linear modeling failed to converge (when parameters were estimated via restricted maximum likelihood as implemented in lme4, or when the posterior distributions of the parameters were estimated via MCMC with Gibbs sampling as implemented in MCMCglmm). We traced this issue of convergence to loci in which all individuals within a treatment combination had 100\% or 0\% methylation, and with diverse levels of methylation in other treatments, making them biologically interesting and desirable to model correctly. As pointed out by Burkner, the approaches used by MCMCglmm can be slow to converge in high-dimensional models with correlated parameters and may depend on conjugate priors. We therefore took a robust approach to analyzing methylation data with Bayesian Regression Models (BRMs) in which the sampling on the posterior distributions on the parameters was accomplished with the No-U-Turn-Sampler (NUTS). This algorithm converges much more quickly for high-dimensional models regardless of whether the priors are conjugate or not.


## Generalized Linear Mixed Models (GLMMs)

Generalized Linear Mixed Models (GLMMs) are an extension to Generalized Linear Models (GLMs) where linear predictors contain random effects. Similar to GLMs, these models can be used form non-normal data as long as the response data comes from a known distribution from the exponential family (including but not limited to normal, poisson, binomial, negative binomial, gamma, beta, and exponential.) GLMMs differ from Linear Mixed Models (LMMs) because they do not require that explanatory variables are related linearly to the response variable, i.e. we can use GLMMs to model nonlinear relationships. Instead, much like a GLM, the outcomes and predictors are linked via some link function g(.) (INPUT RESOURCE??), but unlike GLMs, each linear predictor is a combination of both fixed and random effects (excluding residuals). 

In R, GLMMs are still implemented using the `lme4` package, but using the function `glmer` instead of `lmer.` More in depth tutorials for implementing using `lme4` are listed in the GLMM resources section of this page. 

### Assumptions of GLMMs

* Conditional independence: Oberved data are independent, conditional on some predictors
* Response data come from a known from the exponential family with a known mean variance relationship
* Straight line relationship between some link function of the mean of data and the predictors and random effects
* Random effects are independent of data
* Random effects are normally distributed

### Common Problems with GLMMs - Dispersion

Overdispersion and underdispersion can both be problems when working with GLMMs. Dispersion can be checked using the R package `performance` using the function `check_overdispersion()`. Overdispersion is when data has more variability than a statistical model would predict, while underdispersion happens when data has less variability.
* Overdispersion
	* Overdispersion is a common issue for count data
	* Can be caused by positive correlation, excess variance, and/or distributional assumption violations
	* Can lead to underestimating standard errors of estimates, making a predictor appear significant when it isn't
	* To check for overdispersion, check if the ratio of Pearson's chi-square statistic to it's degrees of freedom is greater than 1
* Underdispersion
	* ADD INFO HERE

### GLMM resources

* [Intro to GLMM](https://stats.oarc.ucla.edu/other/mult-pkg/introduction-to-generalized-linear-mixed-models/)

This resource comes from UCLA's Advanced Research Computing group. It's a quick introduction to GLMMs and a good place to start.

* [GLMMs FAQ](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html)

This page has a ton of information about GLMMs, starting with a more general introduction to GLMMs but also getting into the weeds of different distribution types, model diagnostics and selection, packages for implementing GLMMs, and more.

* [GLMM in R](https://r.qcbs.ca/workshop07/book-en/introduction-to-glmm.html)

This has an introduction to GLMM analysis in R, including information about choosing error distributions and worked examples of fitting Poisson, Negative Binomial, and Poisson-lognormal GLMMs.

* [R Video Tutorial](https://www.youtube.com/watch?v=EibODFjUtqs)

This is a video that also walks through the process of fitting GLMMs in R


### Interpreting GLMMs

* ADD INFORMATION HERE


## How to write about mixed models

* We had a [lab professional development discussion on this](https://docs.google.com/document/d/1jQZkbZbZuWnElYmLUntg5qgh1NG2-yAbsT3zzvmbkZ0/edit#heading=h.btb80w3ha1pf)

* **What to write in a paper?** Check out Zuur and [LME Tutorial](http://www.bodowinter.com/tutorial/bw_LME_tutorial.pdf) for examples.
 
## Frequently asked questions

* **How do you know you want to model an explanatory variable as fixed or random?** If the levels of your explanatory variable represent a subset of an entire population of levels of that variable, then this should be modeled as random. 
	* For more information see [lme4 paper](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) page 6.

* **Do your random effects or subjects appear to vary in the slopes AND intercepts relationships?** Use data visualization to explore the linear relationship across levels of the random explanatory variable(s). An example is shown in [lme4 paper](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) page 4. If so, this suggests a model with random slopes and intercepts.

* **What are the dimensions of linear models (e.g. p, q, n, etc.)?** See [lme4 paper](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) page 8

* **What does $X^TX$ do?** This is a common approach seen in statistics. (WILL ADD MORE)

* **What is REML?** See section 5.6 of Zuur for a great explanation.


